{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from attention import AttentionLayer\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import os\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../datasets/Amazon Reviews/Reviews.csv\"\n",
    "print(os.path.exists(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(data_path,nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)   #dropping na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "\t\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "\t\"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",\n",
    "\t\"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\"hasn't\": \"has not\",\n",
    "\t\"haven't\": \"have not\", \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
    "\t\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\t\"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "\t\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "\t\"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\",\n",
    "\t\"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\",\n",
    "\t\"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\t\"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\",\n",
    "\t\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "\t\"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "\t\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n",
    "\t\"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\t\"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\",\n",
    "\t\"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
    "\t\"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "\t\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\",\n",
    "\t\"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\t\"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "\t\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "\t\"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "\t\"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\",\"we'd've\": \"we would have\",\n",
    "\t\"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
    "\t\"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\",\n",
    "\t\"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "\t\"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\t\"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\",\n",
    "\t\"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\",\n",
    "\t\"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\t\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
    "\t\"y'all\": \"you all\",\t\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\n",
    "\t\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\",\n",
    "\t\"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\t\"you're\": \"you are\", \"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1             Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2    This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
       "3    If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
       "4                                                               Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
       "5    I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there wa...\n",
       "6    This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, ...\n",
       "7                                                               This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!\n",
       "8                                                                        Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too\n",
       "9                                                                  This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Summary Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Good Quality Dog Food\n",
       "1                                Not as Advertised\n",
       "2                            \"Delight\" says it all\n",
       "3                                   Cough Medicine\n",
       "4                                      Great taffy\n",
       "5                                       Nice Taffy\n",
       "6    Great!  Just as good as the expensive brands!\n",
       "7                           Wonderful, tasty taffy\n",
       "8                                       Yay Barley\n",
       "9                                 Healthy Dog Food\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Summary'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_cleaner(text):\n",
    "    newString = re.sub('\"','', text)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens=newString.split()\n",
    "    newString=''\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                 \n",
    "            newString=newString+i+' '  \n",
    "    return newString\n",
    "\n",
    "#Call the above function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(summary_cleaner(t))\n",
    "\n",
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary\n",
    "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "Summary: _START_ good quality dog food  _END_\n",
      "\n",
      "\n",
      "Review: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "Summary: _START_ not as advertised  _END_\n",
      "\n",
      "\n",
      "Review: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "Summary: _START_ delight says it all  _END_\n",
      "\n",
      "\n",
      "Review: looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
      "Summary: _START_ cough medicine  _END_\n",
      "\n",
      "\n",
      "Review: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "Summary: _START_ great taffy  _END_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Review:\",data['cleaned_text'][i])\n",
    "    print(\"Summary:\",data['cleaned_summary'][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the distribution of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=80 \n",
    "max_len_summary=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(data['cleaned_text'],data['cleaned_summary'],test_size=0.1,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "X -- bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "Y -- _START_ good quality dog food  _END_\n",
      "=======================================================================================================\n",
      "1\n",
      "X -- product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "Y -- _START_ not as advertised  _END_\n",
      "=======================================================================================================\n",
      "2\n",
      "X -- confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "Y -- _START_ delight says it all  _END_\n",
      "=======================================================================================================\n",
      "3\n",
      "X -- looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
      "Y -- _START_ cough medicine  _END_\n",
      "=======================================================================================================\n",
      "4\n",
      "X -- great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "Y -- _START_ great taffy  _END_\n",
      "=======================================================================================================\n",
      "5\n",
      "X -- got wild hair taffy ordered five pound bag taffy enjoyable many flavors watermelon root beer melon peppermint grape etc complaint bit much red black licorice flavored pieces kids husband lasted two weeks would recommend brand taffy delightful treat\n",
      "Y -- _START_ nice taffy  _END_\n",
      "=======================================================================================================\n",
      "6\n",
      "X -- saltwater taffy great flavors soft chewy candy individually wrapped well none candies stuck together happen expensive version fralinger would highly recommend candy served beach themed party everyone loved\n",
      "Y -- _START_ great just as good as the expensive brands  _END_\n",
      "=======================================================================================================\n",
      "7\n",
      "X -- taffy good soft chewy flavors amazing would definitely recommend buying satisfying\n",
      "Y -- _START_ wonderful tasty taffy  _END_\n",
      "=======================================================================================================\n",
      "8\n",
      "X -- right mostly sprouting cats eat grass love rotate around wheatgrass rye\n",
      "Y -- _START_ yay barley  _END_\n",
      "=======================================================================================================\n",
      "9\n",
      "X -- healthy dog food good digestion also good small puppies dog eats required amount every feeding\n",
      "Y -- _START_ healthy dog food  _END_\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    print(f\"X -- {x_tr[i]}\")\n",
    "    print(f\"Y -- {y_tr[i]}\")\n",
    "    print(\"=======================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Text tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Summary tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing a tokenizer for summary on training data \n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "X -- [243 423  28   8   5  59   7 332 136  71  28 354 406 797 155   6   7   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "Y -- [ 1 13 14  2  0  0  0  0  0  0]\n",
      "=======================================================================================================\n",
      "1\n",
      "X -- [  144   185    39    10    63  2213   612   543    56     6   102    33\n",
      "   295  1794  1563  1684    56 11513     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "Y -- [  1  34 168  46   2   0   0   0   0   0]\n",
      "=======================================================================================================\n",
      "2\n",
      "X -- [    7  6336  5837   166    28  2862   337  1005   150   740 11514  6977\n",
      "   745 27702 27703   305 16369  3219  2889   928  2910 27704     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "Y -- [   1 4593    2    0    0    0    0    0    0    0]\n",
      "=======================================================================================================\n",
      "3\n",
      "X -- [3176  108   96  196   55   88 2536  901  317  327   14    2  430  180\n",
      "  151 1720 1361 2394 2078 2382  195 1290 7485 2394  183  826   40  566\n",
      "  369  195 1290 1020  195  264  330  534 1202  167  195  192  183   36\n",
      "    3   63 2394 2496  167  898   35   77  133 1138   13 6137   42    3\n",
      " 5042   66  315  317  327  263   35  949  667  450  706   84  201  265\n",
      "  184  823  136  794  187  701 3805 3897    0    0]\n",
      "Y -- [ 251 2479   36  579 2315   12   50  579   89    2]\n",
      "=======================================================================================================\n",
      "4\n",
      "X -- [   98 27705   978    67  1861     4  2214   464  1861  1838  8035   646\n",
      "     6 10958   652     5  1061   161   978   860 12106    26   104  2781\n",
      "  1893  2334     4   436  2214    93  8477  4869 10959  2414   637  2507\n",
      "  5170  8035   200   146  1018   161   978  5043   799   909   238  1916\n",
      "   890  2079     4   200   253  3177   277    56  2023  5043   799    58\n",
      "   369   566  2299   147  2497   329   261   672   576     5    61   440\n",
      "   862   978  1062   116     4   209   244 14885]\n",
      "Y -- [   1    7   37  912   62   68  886 2663    2    0]\n",
      "=======================================================================================================\n",
      "5\n",
      "X -- [  60  328 2572  491   21  153   55  904  198   61 5606  527  926   22\n",
      " 4371   73    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Y -- [  1 262 194   2   0   0   0   0   0   0]\n",
      "=======================================================================================================\n",
      "6\n",
      "X -- [ 470 1019  172   98    4  173   79  255 4870   51 1550 1074   50  181\n",
      "  162  766  118 2579   29  384  208 3651 4870  140   51   52  382   26\n",
      "   51   41 1162  403 2900   79  638  163   76   56    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Y -- [  1  11 395  44   9   2   0   0   0   0]\n",
      "=======================================================================================================\n",
      "7\n",
      "X -- [ 4810  6236  1564    14   107  3520     3   118  1312   233  7648     3\n",
      "  4760    30   123  7648   961  4811  3474 11515  1738    44    39   339\n",
      "     8   803  2498   597   301   191   331   491    29  1480     8   331\n",
      "    27    73    43    15    62   858    83    15  3114    51   301  4547\n",
      "  1534   204    20    30   765     8    58    64  2863    48   366   261\n",
      "     1   200    70   606   230   187    66    99   220   162   250   484\n",
      "  4626   153    81    32   498     2     4    43]\n",
      "Y -- [ 1  9 96 11 38  2  0  0  0  0]\n",
      "=======================================================================================================\n",
      "8\n",
      "X -- [  46  270 3157  372  664  121 2653   55 4871  483  766  369   15 4156\n",
      " 1274 1711  271  180 3250 3269  222 1133  621    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Y -- [   1 1966  162    2    0    0    0    0    0    0]\n",
      "=======================================================================================================\n",
      "9\n",
      "X -- [   9  815  535   86    9    2  104  493 1415  406 1691 1464 1585 2053\n",
      "  219 6032 1415 8478    9  613  146  100 2165  108  304  897  406    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Y -- [  1  17 609   2   0   0   0   0   0   0]\n",
      "=======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    print(f\"X -- {x_tr[i]}\")\n",
    "    print(f\"Y -- {y_tr[i]}\")\n",
    "    print(\"=======================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 500)      25785500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 80, 500), (N 2002000     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 80, 500), (N 2002000     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 500)    7048000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 80, 500), (N 2002000     lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 14096)  14110096    concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 55,452,096\n",
      "Trainable params: 55,452,096\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session() \n",
    "latent_dim = 500 \n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Set up the decoder. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79516 samples, validate on 8836 samples\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:], \\\n",
    "                  epochs=50, callbacks=[es], batch_size=512, \\\n",
    "                  validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the diagnostic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=x_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "      if(i!=0):\n",
    "        newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_val)):\n",
    "  print(\"Review:\",seq2text(x_val[i]))\n",
    "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
    "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
